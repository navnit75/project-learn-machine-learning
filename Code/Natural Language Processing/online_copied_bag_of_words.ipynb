{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"online_copied_bag_of_words.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"VwK5-9FIB-lu"},"source":["# Natural Language Processing"]},{"cell_type":"markdown","metadata":{"id":"X1kiO9kACE6s"},"source":["## Importing the libraries"]},{"cell_type":"code","metadata":{"id":"EUIYtsF76YlV"},"source":["import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import joblib\n"," \n","projDir = 'C:/Users/neelkanth mehta/Documents/Udemy/udemy-machine_learning/Section 34 - NLP'\n","datafile= os.path.join(projDir,'Restaurant_Reviews.tsv')\n"," \n"," \n","'''Loading and preprocessing dataset'''\n","import re\n","import nltk\n"," \n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","from nltk.stem.porter import PorterStemmer\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n"," \n"," \n","def generate_corpus(df:pd.DataFrame, verbose=False) -> pd.DataFrame:\n","    '''\n","    Generates sparse matrix of corpus of words from the given reviews\n","    and returns X and y\n","    \n","    inputs:\n","        df -> pd.DataFrame() object containing reviews and likes\n","        verbose --> bool whether would like to print the corpus sample\n","        \n","    outputs:\n","        X -> np.array() object, which is a sparse matrix of corpus\n","        y -> np.array() object of likes column in the original dataframe\n","    '''\n","    corpus = []\n","    \n","    # processing text\n","    for i in range(0, df.shape[0]):\n","        review = re.sub('[^a-zA-Z]', ' ', df.loc[i,'Review'])\n","        review = review.lower()\n","        review = review.split()\n","        ps = PorterStemmer()\n","        review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n","        review = ' '.join(review)\n","        corpus.append(review)\n","    \n","    # printing the output\n","    if verbose == True:\n","        print('corpus  \\n')\n","        print(pd.Series(corpus).sample(10))\n","        print('')\n","    \n","    # Fitting and transforming the corpus with CountVectorizer()\n","    count_vect = CountVectorizer(max_features=1500)\n","    X = pd.DataFrame(count_vect.fit_transform(corpus).toarray())\n","    y = df['Liked']\n","    \n","    return X, y\n","    \n"," \n","def split_dataset(X, y, test_size=0.2, shuffle=True, random_state=0):\n","    '''\n","    Uses train_test_split function of sklearn library to split the dataset\n","    \n","    inputs:\n","        X -> np.array() object, which is a sparse matrix of corpus \n","        y -> np.array() object of likes column in the original dataframe\n","        test_size -> float between 0 and 1\n","        shuffle -> boolean object\n","        stratisfy -> feature to base stratas on    \n","        random_state -> integer\n","    \n","    outputs: X_train, y_train, X_test, y_test np.array() objects\n","    '''\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, shuffle=shuffle, random_state=random_state)\n","    return X_train, y_train, X_test, y_test\n"," \n"," \n","'''Fitting model and scoring'''\n","def classification_model(X_train, y_train, X_test, y_test, model='LogisticRegression', save=False, graph=False, metrics:list=['accuracy_score'], **kwargs): # , rs=0\n","    '''\n","    Fits, saves, predicts, outputs performance and produces graphs for select classification model out of 'LogReg', 'KNN', 'SVC', 'SVC_rbf', 'NaiveBayes', 'tree' or 'forest'\n"," \n","    inputs:\n","        X_train -> nd array. X train values\n","        y_train -> 1d array. y train values\n","        X_test -> nd array. X test values\n","        y_test -> 1d array. y test values.\n","        model -> specify a model, LogReg by default. Enter string value from the above choice of models.\n","        rs -> integer, 0 by default. Enter any integer value\n","        save -> boolean, False by default. Enter True if you want to pickle the model\n","        graph -> boolean, False by default. enter True if you want a graph\n"," \n","    output:\n","        perf_stats -> pd.DataFrame() object of selected performance statistics\n","        cm -> confusion matrix\n","    '''\n"," \n","    # Instantiating model\n","    \n","    mod = eval(model)(**kwargs)\n","    \n","    # Fitting models\n","    mod.fit(X, y)\n"," \n","    # Pikling model\n","    if save == True:\n","        joblib.dump(value=mod, filename=os.path.join(projDir, str(model)+'.pickle'))\n"," \n","    # Model evaluation\n","    y_pred = mod.predict(X_test)\n","    perf = {i: eval(i)(y_test, y_pred) for i in metrics}\n","    perf_stats = pd.Series(list(perf.values()), index=list(perf.keys()), name=model)\n"," \n","    cm = confusion_matrix(y_test, y_pred)\n","    cm = np.vstack((cm[1][::-1], cm[0][::-1]))\n"," \n","    return perf_stats, cm\n"," \n"," \n","if __name__ == '__main__':\n"," \n","    # Data prep\n","    dataset = pd.read_csv(datafile, delimiter='\\t', quoting=3)\n","    X, y = generate_corpus(df=dataset)\n","    X_train, y_train, X_test, y_test = split_dataset(X, y)\n"," \n","    # Classification model execution\n","    logreg, _ = classification_model(X_train, y_train, X_test, y_test, model='LogisticRegression', metrics=['accuracy_score', 'precision_score', 'recall_score', 'f1_score'], penalty='l1', C=0.2, solver='liblinear', random_state=0, save=True)\n"," \n","    KNN, _ = classification_model(X_train, y_train, X_test, y_test, model='KNeighborsClassifier', metrics=['accuracy_score', 'precision_score', 'recall_score', 'f1_score'], weights='distance', p=2)\n"," \n","    svc, _ = classification_model(X_train, y_train, X_test, y_test, model='SVC', metrics=['accuracy_score', 'precision_score', 'recall_score', 'f1_score'], kernel='linear', random_state=0, gamma='auto', C=0.1)\n"," \n","    svc_r, _ = classification_model(X_train, y_train, X_test, y_test, model='SVC', metrics=['accuracy_score', 'precision_score', 'recall_score', 'f1_score'], kernel='rbf', random_state=0, gamma='auto', C=0.1)\n"," \n","    GNB, _ = classification_model(X_train, y_train, X_test, y_test, model='GaussianNB', metrics=['accuracy_score', 'precision_score', 'recall_score', 'f1_score'])\n"," \n","    tree, _ = classification_model(X_train, y_train, X_test, y_test, model='DecisionTreeClassifier', metrics=['accuracy_score', 'precision_score', 'recall_score', 'f1_score'], criterion='entropy', max_depth=5, random_state=0)\n"," \n","    forest, _ = classification_model(X_train, y_train, X_test, y_test, model='RandomForestClassifier', metrics=['accuracy_score', 'precision_score', 'recall_score', 'f1_score'], n_estimators=22, criterion='entropy', random_state=0, max_depth=5)\n"," \n","    print(pd.concat([logreg, KNN, svc, svc_r, GNB, tree, forest], axis=1).T)"],"execution_count":null,"outputs":[]}]}